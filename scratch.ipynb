{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551ea72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta, datetime, date\n",
    "from itertools import product\n",
    "from tabulate import tabulate\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone, ClassifierMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay, \n",
    "    roc_curve, RocCurveDisplay, auc, roc_auc_score, f1_score,\n",
    "    precision_recall_curve, PrecisionRecallDisplay, \n",
    "    precision_score, recall_score, average_precision_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "\n",
    "import ta\n",
    "from ta.trend import MACD, ADXIndicator\n",
    "from scipy.signal import argrelextrema\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "309f3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ===== serializing objects =====\n",
    "# ===============================\n",
    "def save_pkl(path, data):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Saved data to {path}.\")\n",
    "\n",
    "def read_pkl(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{path} does not exist.\")\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Loaded data from {path}.\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# =======================\n",
    "# ===== data loader =====\n",
    "# =======================\n",
    "\n",
    "def get_data(\n",
    "        ticker, \n",
    "        start_date='1999-01-01', \n",
    "        end_date=None, \n",
    "        save_csv=False\n",
    "):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    filename = f\"data/{ticker.lower()}.csv\"\n",
    "\n",
    "    # add one day to end_date because yf.download end is not inclusive\n",
    "    if end_date is not None:\n",
    "        end_date = pd.to_datetime(end_date).date()\n",
    "        end_date = (end_date + timedelta(days=1)).isoformat()\n",
    "\n",
    "    data = yf.download(\n",
    "        ticker.upper(), \n",
    "        start=start_date, \n",
    "        end=end_date, \n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    # Handle empty or failed download\n",
    "    if data.empty:\n",
    "        print(f\"No data found for {ticker}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Flatten column headers if it's a MultiIndex (e.g., from group_by='ticker')\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        data.columns = data.columns.get_level_values(0)\n",
    "    \n",
    "    data['Ticker'] = ticker.lower()\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data.columns = [col.lower() for col in data.columns]\n",
    "\n",
    "    if save_csv:\n",
    "        data.to_csv(filename)\n",
    "        print(f\"Saved data for {ticker} to {filename}\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "# get list of tickers in s&p500\n",
    "def get_sp500(): # accurate as of 2025-07-31; may need update in the future\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    sp500_df = pd.read_html(url, header=0)[0]\n",
    "    sp500_tickers = sp500_df['Symbol'].tolist()\n",
    "    sp500_tickers = [t.replace('.', '-') for t in sp500_tickers] \n",
    "    # should exclude goog, foxa, nws (as of 2025-07-31)\n",
    "    excluded_tickers = {'GOOG', 'FOXA', 'NWS'}\n",
    "    sp500_tickers = [t for t in sp500_tickers if t not in excluded_tickers]\n",
    "    # return lower case for consistency\n",
    "    sp500_tickers = [t.lower() for t in sp500_tickers]\n",
    "    return sp500_tickers # a list of string\n",
    "\n",
    "\n",
    "# get metadata\n",
    "def get_metadata(ticker, sp500_tickers=None, sector_only=False):\n",
    "    try:\n",
    "        info = yf.Ticker(ticker.upper()).info\n",
    "        if sector_only:\n",
    "            return {\n",
    "            'ticker': ticker,\n",
    "            'sector': yf.Ticker(ticker.upper()).info.get('sector'),\n",
    "        }\n",
    "        else:\n",
    "            if sp500_tickers is None: \n",
    "                sp500_tickers = get_sp500()\n",
    "            return {\n",
    "                'ticker': ticker,\n",
    "                'sector': info.get('sector'),\n",
    "                # 'industry': info.get('industry'), \n",
    "                # # try not to ohe this for now because its a lot more granular\n",
    "                'market_cap': info.get('marketCap'),\n",
    "                'avg_volume': info.get('averageVolume'),\n",
    "                'beta': info.get('beta'),\n",
    "                'is_sp500': ticker in sp500_tickers\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {ticker}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# get a df that contains tickers from s&p500 and their sectors\n",
    "def get_sp500_tickers_sectors_mindates(\n",
    "        path='files/sp500_tickers_sectors_mindates.pkl', \n",
    "        sp500_tickers=None, \n",
    "        redo=False\n",
    "):\n",
    "    if os.path.exists(path) and not redo:\n",
    "        return read_pkl(path) # a pd.DataFrame\n",
    "    else: \n",
    "        if sp500_tickers is None:\n",
    "            sp500_tickers = get_sp500()\n",
    "        ls = []\n",
    "        for i in tqdm(sp500_tickers, desc=\"Processing tickers\"):\n",
    "            d = get_metadata(i,sp500_tickers,sector_only=True)\n",
    "            d['mindate'] = yf.Ticker(i.upper()).history(period='max').index.min().date()\n",
    "            ls.append(d)\n",
    "        df = pd.DataFrame(ls)\n",
    "        save_pkl(path, df)\n",
    "        return df\n",
    "    \n",
    "\n",
    "# =======================\n",
    "# ===== feature eng =====\n",
    "# =======================\n",
    "\n",
    "def feature_engineering(df): # for trading at open tomorrow\n",
    "    # bollinger bands and rsi\n",
    "    df = df.copy()\n",
    "    df['sma30'] = df['close'].rolling(30).mean() # wont be used \n",
    "    df['sma10'] = df['close'].rolling(10).mean() # wont be used\n",
    "    df['sma_diff'] = df['sma10'] - df['sma30']\n",
    "    df['sma_slope'] = df['sma10'].diff()\n",
    "    df['std30'] = df['close'].rolling(30).std() # wont be used \n",
    "    df['bollinger_upper'] = df['sma30'] + 2 * df['std30'] # wont be used \n",
    "    df['bollinger_lower'] = df['sma30'] - 2 * df['std30'] # wont be used \n",
    "    df['percent_b'] = (df['close'] - df['bollinger_lower']) / (df['bollinger_upper'] - df['bollinger_lower'])\n",
    "    df['bollinger_z'] = (df['close'] - df['sma30']) / df['std30']\n",
    "    df['price_near_lower_bb'] = (df['close'] <= df['bollinger_lower'] * 1.01).astype(int)\n",
    "    df['rsi14'] = ta.momentum.RSIIndicator(df['close'], window=14).rsi()    \n",
    "    df['prod_bollingerz_rsi'] = df['percent_b'] * df['rsi14']\n",
    "\n",
    "    # Detect local lows\n",
    "    df['rsi_smooth'] = df['rsi14'].rolling(3).mean() # wont be used \n",
    "    rsi_vals = df['rsi_smooth'].values\n",
    "    local_lows = argrelextrema(rsi_vals, np.less, order=5)[0]\n",
    "    df['rsi_local_low'] = 0\n",
    "    df.iloc[local_lows, df.columns.get_loc('rsi_local_low')] = 1\n",
    "\n",
    "    # some other useful features  \n",
    "    df['daily_return'] = df['open'].pct_change()\n",
    "    df['rolling_volatility14'] = df['daily_return'].rolling(window=14).std()\n",
    "    df['atr'] = ta.volatility.AverageTrueRange(high=df['high'], low=df['low'], close=df['close']).average_true_range()\n",
    "\n",
    "    # GARCH(1,1) on returns\n",
    "    returns = df['open'].pct_change().dropna() * 100 # in percent\n",
    "    am = arch_model(returns, vol='Garch', p=1, q=1, mean='constant')\n",
    "    res = am.fit(disp='off')\n",
    "    df['garch_vol'] = res.conditional_volatility # in percent\n",
    "\n",
    "    # time related features\n",
    "    # df['year'] = df.index.year\n",
    "    year_min = df.index.year.min()\n",
    "    df['year_since'] = df.index.year-year_min\n",
    "    \n",
    "    df['month'] = df.index.month\n",
    "    df['week'] = df.index.isocalendar().week\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "\n",
    "    # trend following contextual features\n",
    "    # sma_slope (already added)\n",
    "    macd = MACD(close=df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    # df['macd'] = macd.macd()                   # EMA12 - EMA26\n",
    "    # df['macd_signal'] = macd.macd_signal()     # 9-day EMA of MACD\n",
    "    df['macd_diff'] = macd.macd_diff()         # Histogram: MACD - Signal\n",
    "\n",
    "    adx = ADXIndicator(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
    "\n",
    "    df['adx'] = adx.adx()              # Trend strength\n",
    "    df['adx_pos'] = adx.adx_pos()      # +DI; wont be used\n",
    "    df['adx_neg'] = adx.adx_neg()      # -DI; wont be used\n",
    "\n",
    "    # df['macd_uptrend'] = (df['macd_diff'] > 0).astype(int)\n",
    "    df['strong_trend'] = (df['adx'] > 25).astype(int)\n",
    "    df['up_trend_context'] = ((df['adx'] > 25) & (df['adx_pos'] > df['adx_neg'])).astype(int)\n",
    "    df['down_trend_context'] = ((df['adx'] > 25) & (df['adx_neg'] > df['adx_pos'])).astype(int)\n",
    "\n",
    "    # df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# useful for adding information from market trend e.g. spy, qqq\n",
    "def market_trend(etf:str, end_date = None, load_csv = True, save_csv = False):\n",
    "    csv_path = f\"data/{etf}.csv\"\n",
    "    if load_csv and os.path.exists(csv_path):\n",
    "            df_etf = pd.read_csv(csv_path, index_col=0, parse_dates=True)\n",
    "    else:\n",
    "        df_etf = get_data(etf, end_date=end_date)\n",
    "\n",
    "    df_etf['sma10'] = df_etf['close'].rolling(10).mean()\n",
    "    df_etf['sma20'] = df_etf['close'].rolling(20).mean()\n",
    "    df_etf['sma50'] = df_etf['close'].rolling(50).mean()\n",
    "    df_etf['sma200'] = df_etf['close'].rolling(200).mean()\n",
    "    df_etf['trend_10_50'] = (df_etf['sma10'] > df_etf['sma50']).astype(int)\n",
    "    df_etf['trend_20_50'] = (df_etf['sma20'] > df_etf['sma50']).astype(int)\n",
    "    df_etf['trend_50_200'] = (df_etf['sma50'] > df_etf['sma200']).astype(int)\n",
    "    df = df_etf[['trend_10_50','trend_20_50','trend_50_200']]\n",
    "    if save_csv:\n",
    "        df.to_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering_market(df, etf:str, etfs=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    if etf not in etfs:\n",
    "        df_etf = market_trend(etf)\n",
    "    else:\n",
    "        df_etf = etfs[etf][:df.index.max()]\n",
    "\n",
    "    df = df.merge(df_etf['trend_10_50'].rename(f'{etf}_trend_10_50'), left_index=True, right_index=True, how='left')\n",
    "    df = df.merge(df_etf['trend_20_50'].rename(f'{etf}_trend_20_50'), left_index=True, right_index=True, how='left')\n",
    "    df = df.merge(df_etf['trend_50_200'].rename(f'{etf}_trend_50_200'), left_index=True, right_index=True, how='left')\n",
    "    return df\n",
    "        \n",
    "\n",
    "def feature_engineering_metadata(df, sp500_tickers):\n",
    "    df = df.copy()\n",
    "    if 'ticker' not in df.columns:\n",
    "        raise KeyError(\"df does not contain ticker info\")\n",
    "    if df['ticker'].nunique() != 1: \n",
    "        raise ValueError(f\"Expected exactly 1 unique ticker, but got {df['ticker'].nunique()}\")\n",
    "    ticker = df['ticker'].iloc[0]\n",
    "    md = get_metadata(ticker, sp500_tickers=sp500_tickers)\n",
    "    for k, v in md.items():\n",
    "        df[k] = v \n",
    "    return df\n",
    "\n",
    "# ===========================\n",
    "# ===== target creation =====\n",
    "# ===========================\n",
    "\n",
    "# trading at open tomorrow (t+1)\n",
    "# based on today's data (ohlcv and more), decide whether to long tomorrow\n",
    "def create_target_long(df_orig, timing = 'open', lookahead=5, strategy='static', **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    entry: assume always enter at open\n",
    "    exit: timing is \"exit\" timing, can either be 'open' or 'high'\n",
    "    use 'high' when your platform performs auto exit for you when price exceeds your profit threshold \n",
    "    use 'open' for simplification (only trade at open)\n",
    "\n",
    "    strategy: either 'static' or 'dynamic'\n",
    "    static: use a set (expected return rate) threshold throughout, default is 0.01\n",
    "    kwargs for static: threshold \n",
    "    dynamic: mimic the entry_exit function below, use a profit loss ratio scaled by volatility\n",
    "    kwargs: vol (one of 'atr', 'garch_vol'), upper = 0.95, take_profit (default 1.2)\n",
    "    upper is the quantile that cap the volatility (so that won't have extremely high threshold caused by high volatility)\n",
    "    (no need stop loss here; everything not over profit threshold will be labeled 0)\n",
    "\n",
    "    label as 1 if max return over the next 'lookahead' days is >= threshold, else label as 0.\n",
    "    only returns a series (ie y), not a dataframe\n",
    "    \"\"\"\n",
    "    df = df_orig.copy()\n",
    "    if timing not in ['open','high']: \n",
    "        raise ValueError(f\"Invalid timing value: {timing}. Expected 'open' or 'high'.\") \n",
    "    if strategy == 'static':\n",
    "        allowed = {'threshold'}\n",
    "    elif strategy == 'dynamic':\n",
    "        allowed = {'vol', 'upper', 'take_profit'}\n",
    "    else: \n",
    "        raise ValueError(f\"Invalid strategy value: {strategy}. Expected 'static' or 'dynamic'.\") \n",
    "\n",
    "    for k in kwargs:\n",
    "        if k not in allowed:\n",
    "            raise ValueError(f\"Unexpected keyword argument: '{k}' for strategy='{strategy}'\")\n",
    "\n",
    "\n",
    "    df['price_tmrw'] = df['open'].shift(-1) # trade at open next day\n",
    "\n",
    "    df['seq_index'] = range(len(df))\n",
    "    future_max_list = []\n",
    "    for i in df['seq_index']:\n",
    "        if i + 1 + lookahead <= len(df):\n",
    "            window = df[timing].iloc[i+1 : i+1+lookahead]\n",
    "            future_max_list.append(window.max())\n",
    "        else:\n",
    "            future_max_list.append(np.nan)\n",
    "\n",
    "    df['future_max'] = future_max_list\n",
    "    df['future_return'] = (df['future_max'] - df['price_tmrw']) / df['price_tmrw']\n",
    "\n",
    "    if strategy == 'static':\n",
    "        threshold = kwargs.get('threshold', 0.01)\n",
    "        df['threshold'] = threshold \n",
    "    elif strategy == 'dynamic': \n",
    "        vol = kwargs.get('vol')\n",
    "        if vol not in ['atr', 'garch_vol']:\n",
    "            raise ValueError(\"Invalid or missing 'vol'. Must be one of: 'atr', 'garch_vol'\")\n",
    "        if vol not in df.columns:\n",
    "            raise KeyError(f\"Volatility column '{vol}' not found in DataFrame\")\n",
    "        upper = kwargs.get('upper', 0.95)\n",
    "        vol_cap = df[vol].quantile(upper)\n",
    "        take_profit = kwargs.get('take_profit', 1)\n",
    "        df['effective_vol'] = df[vol].clip(upper=vol_cap)\n",
    "\n",
    "        df['threshold'] = df['effective_vol']*take_profit/100 \n",
    "    else: \n",
    "        raise ValueError(f\"Invalid strategy value: {strategy}. Expected 'static' or 'dynamic'.\") \n",
    "    \n",
    "    df['target_long'] = (df['future_return'] >= df['threshold']) \\\n",
    "        .where(df['future_return'].notna()) \\\n",
    "        .astype('Int64')  \n",
    "    \n",
    "    return df_orig.merge(df[['target_long']], how='left', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# ===== wrangling (for all features and target) =====\n",
    "# ===================================================\n",
    "def wrangling(\n",
    "        df_ohlcv, \n",
    "        etfs=None, \n",
    "        sp500_tickers=None,\n",
    "        **kwargs\n",
    "):\n",
    "    df = feature_engineering(df_ohlcv)\n",
    "    df = feature_engineering_market(df, 'spy', etfs)\n",
    "    df = feature_engineering_market(df, 'qqq', etfs)\n",
    "    df = feature_engineering_metadata(df, sp500_tickers=sp500_tickers)\n",
    "    # drop na first just to be safe for running target creation \n",
    "    # df.dropna(inplace=True)\n",
    "    df = create_target_long(df, **kwargs)\n",
    "    return df\n",
    "    \n",
    "\n",
    "# ============================================================\n",
    "# ===== generate pkl file for data from multiple tickers =====\n",
    "# ============================================================\n",
    "\n",
    "def get_data_global_model(\n",
    "        list_of_tickers, \n",
    "        path='files/data_global.pkl', \n",
    "        end_date=None, \n",
    "        redo=False, \n",
    "        **kwargs\n",
    "):\n",
    "    if os.path.exists(path) and not redo:\n",
    "        d = read_pkl(path) # a dict\n",
    "        print(f'loaded existing {path} with {len(d)} tickers')\n",
    "    else: \n",
    "        d = {}\n",
    "        print('no existing pkl found; starting fresh')\n",
    "\n",
    "    for i in tqdm(list_of_tickers, desc=\"Processing tickers\"):\n",
    "        if i in d:\n",
    "            continue\n",
    "        try:\n",
    "            ohlcv = get_data(i, end_date=end_date, save_csv=False)\n",
    "            df = wrangling(ohlcv, **kwargs)\n",
    "            d[i] = {\n",
    "                'ohlcv': ohlcv,\n",
    "                'prepped_data': df,\n",
    "                'as_of': ohlcv.index.max().date()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {i}: {e}\", flush=True)\n",
    "\n",
    "    save_pkl(path, d)\n",
    "    return d\n",
    "\n",
    "\n",
    "# =======================\n",
    "# ===== XGB Wrapper =====\n",
    "# =======================\n",
    "\n",
    "class XGB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.xgb_params = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y)\n",
    "        pos = np.sum(y == 1)\n",
    "        neg = np.sum(y == 0)\n",
    "        scale_pos_weight = neg / pos if pos != 0 else 1.0\n",
    "\n",
    "        self.model = XGBClassifier(\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            objective='binary:logistic',\n",
    "            **self.xgb_params\n",
    "        )\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.xgb_params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.xgb_params.update(params)\n",
    "        return self\n",
    "\n",
    "\n",
    "# =======================\n",
    "# ===== backtesting =====\n",
    "# =======================\n",
    "\n",
    "def pred_proba_to_signal(y_proba, threshold=0.5):\n",
    "    return (y_proba >= threshold).astype(int)\n",
    "\n",
    "def entry_exit(df, use_vol=None, take_profit=1, stop_loss=1, min_return = 0.01): \n",
    "    '''\n",
    "    FOR EACH INSTRUMENT (don't use the aggregated one that contains multiple tickers)\n",
    "    takes in the X_test dataframe containing model signals,\n",
    "    returns a df that contains entry and exit dates, prices, returns, and holding days\n",
    "    use_vol: either 'atr' or 'garch_vol'\n",
    "    take_profit and stop loss as percentage\n",
    "    '''\n",
    "    # if date as index\n",
    "    if pd.api.types.is_datetime64_any_dtype(df.index): \n",
    "        df = df.reset_index().rename(columns={'Date': 'date'})\n",
    "\n",
    "    trades = []\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    if use_vol not in [None, 'atr', 'garch_vol']:\n",
    "        raise ValueError(\"use_vol must be one of: None, 'atr' or 'garch_vol'\")\n",
    "    \n",
    "    if use_vol == 'atr':\n",
    "        multiplier = df['atr']/ df['open']\n",
    "    elif use_vol == 'garch_vol':\n",
    "        vol_cap = df['garch_vol'].quantile(0.9)\n",
    "        multiplier = (df['garch_vol'].clip(upper=vol_cap)) / 100\n",
    "    else:\n",
    "        multiplier = pd.Series(0.01, index=df.index)\n",
    "    effective_profit_threshold = (take_profit * multiplier).clip(lower=min_return)\n",
    "\n",
    "    while i < n - 6:  # we need at least 5 days ahead, plus trading at open tomorrow\n",
    "        if df['model_signal'].iloc[i] == 1:\n",
    "            entry_date = df['date'].iloc[i+1]\n",
    "            entry_price = df['open'].iloc[i+1]\n",
    "            exit_price = None\n",
    "            exit_date = None\n",
    "            holding = None\n",
    "            exit_reason = None\n",
    "\n",
    "            for j in range(1, 6):  # check up to 5 days ahead\n",
    "                if i + 1 + j >= n:\n",
    "                    break\n",
    "\n",
    "                next_price = df['open'].iloc[i + 1 + j]\n",
    "                ret = (next_price - entry_price) / entry_price\n",
    "\n",
    "                # Exit Conditions\n",
    "                if ret >= effective_profit_threshold.iloc[i]:  # profit target\n",
    "                    exit_price = next_price\n",
    "                    exit_date = df['date'].iloc[i + 1 + j]\n",
    "                    holding = j\n",
    "                    exit_reason = 'profit_target'\n",
    "                    break\n",
    "                elif ret <= -stop_loss * multiplier.iloc[i]:  # stop loss\n",
    "                    exit_price = next_price\n",
    "                    exit_date = df['date'].iloc[i + 1 + j]\n",
    "                    holding = j\n",
    "                    exit_reason = 'stop_loss'\n",
    "                    break\n",
    "                elif df['open'].iloc[i + 1 + j] >= df['sma30'].iloc[i + 1 + j]:  # revert to SMA30\n",
    "                    exit_price = next_price\n",
    "                    exit_date = df['date'].iloc[i + 1 + j]\n",
    "                    holding = j\n",
    "                    exit_reason = 'revert_to_sma30'\n",
    "                    break\n",
    "\n",
    "            if exit_price is None:\n",
    "                # Max holding (5th day)\n",
    "                exit_price = df['open'].iloc[i + 1 + 5]\n",
    "                exit_date = df['date'].iloc[i + 1 + 5]\n",
    "                exit_reason = 'max_holding_expired'\n",
    "                holding = 5\n",
    "\n",
    "            trade_return = (exit_price - entry_price) / entry_price\n",
    "            trades.append({\n",
    "                'entry_date': entry_date,\n",
    "                'exit_date': exit_date,\n",
    "                'entry_price': entry_price,\n",
    "                'exit_price': exit_price,\n",
    "                'return': trade_return,\n",
    "                'holding_days': holding,\n",
    "                'exit_reason': exit_reason\n",
    "            })\n",
    "\n",
    "            i = i + holding  # skip to the day after exit\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    if len(trades) > 0:\n",
    "        return pd.DataFrame(trades)\n",
    "    \n",
    "    return pd.DataFrame(columns=[\n",
    "        'entry_date',\n",
    "        'exit_date',\n",
    "        'entry_price',\n",
    "        'exit_price',\n",
    "        'return',\n",
    "        'holding_days',\n",
    "        'exit_reason'\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_cagr(df_trades):\n",
    "    if len(df_trades) > 0:\n",
    "        start_date = df_trades['entry_date'].min()\n",
    "        end_date = df_trades['exit_date'].max()\n",
    "        n_years = (end_date - start_date).days / 365.25\n",
    "        capital = 1\n",
    "        for r in df_trades['return']:\n",
    "            capital *= (1 + r)\n",
    "        cagr = capital ** (1 / n_years) - 1\n",
    "        return cagr\n",
    "    return 0\n",
    "\n",
    "def get_sharpe(df_trades, total_trading_days):\n",
    "    if len(df_trades) > 0 and total_trading_days > 0:\n",
    "        ret_mean = df_trades['return'].mean()\n",
    "        ret_std = df_trades['return'].std()\n",
    "        n_trades = len(df_trades)\n",
    "        trades_per_year = (n_trades/total_trading_days) * 252\n",
    "        return (ret_mean/ret_std) * np.sqrt(trades_per_year)\n",
    "    return 0\n",
    "\n",
    "def get_expectancy(df_trades):\n",
    "    if len(df_trades) == 0:\n",
    "        return 0\n",
    "\n",
    "    wins = df_trades[df_trades['return'] > 0]\n",
    "    losses = df_trades[df_trades['return'] <= 0]\n",
    "\n",
    "    win_rate = len(wins) / len(df_trades)\n",
    "    loss_rate = 1 - win_rate\n",
    "\n",
    "    avg_win = wins['return'].mean() if not wins.empty else 0\n",
    "    avg_loss = abs(losses['return'].mean()) if not losses.empty else 0\n",
    "\n",
    "    expectancy = win_rate * avg_win - loss_rate * avg_loss\n",
    "    return expectancy\n",
    "\n",
    "def backtest(\n",
    "        X_backtest_input, \n",
    "        model, \n",
    "        proba_threshold = 0.5, \n",
    "        use_vol=None, \n",
    "        take_profit=1, \n",
    "        stop_loss=1, \n",
    "        min_return = 0.01,\n",
    "        X_model_input=None\n",
    "):\n",
    "    if X_model_input is None:\n",
    "        X_model_input = X_backtest_input\n",
    "\n",
    "    trade_stats = {} \n",
    "\n",
    "    y_proba = model.predict_proba(X_model_input)[:, 1]\n",
    "    trade_stats['max_proba'] = y_proba.max()\n",
    "\n",
    "    signals = pred_proba_to_signal(y_proba, threshold=proba_threshold)\n",
    "    X_test_signal = X_backtest_input.copy()\n",
    "    X_test_signal = X_test_signal.assign(model_signal=signals, y_proba=y_proba)\n",
    "\n",
    "    df_trade = entry_exit(X_test_signal, use_vol, take_profit, stop_loss, min_return)\n",
    "    if len(df_trade) > 0:\n",
    "        total_holding_days = df_trade['holding_days'].sum()\n",
    "        total_trading_days = len(X_test_signal)\n",
    "        if total_trading_days > 0:\n",
    "            holding_time_percentage = total_holding_days/total_trading_days\n",
    "        else: \n",
    "            holding_time_percentage = 0\n",
    "\n",
    "        n_trades = len(df_trade)\n",
    "        n_wins = len(df_trade[df_trade['return'] > 0])\n",
    "        if n_trades > 0:\n",
    "            win_rate = n_wins/n_trades\n",
    "        else: \n",
    "            win_rate = 0\n",
    "\n",
    "        cagr = get_cagr(df_trade)\n",
    "        sharpe = get_sharpe(df_trade, total_holding_days)\n",
    "        expectancy = get_expectancy(df_trade)\n",
    "\n",
    "        trade_stats = {\n",
    "            'exit_reason_spread': df_trade['exit_reason'].value_counts(),\n",
    "            'holding_days_spread': df_trade['holding_days'].value_counts(),\n",
    "            'total_trading_days': total_trading_days,\n",
    "            'total_holding_days': total_holding_days,\n",
    "            'holding_time_percentage': holding_time_percentage,\n",
    "            'n_trades': n_trades,\n",
    "            'n_wins': n_wins,\n",
    "            'win_rate': win_rate,\n",
    "            'cagr': cagr,\n",
    "            'sharpe': sharpe,\n",
    "            'expectancy': expectancy,\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        trade_stats = {\n",
    "            'exit_reason_spread': 'not available',\n",
    "            'holding_days_spread': 'not available',\n",
    "            'total_trading_days': 0,\n",
    "            'total_holding_days': 0,\n",
    "            'holding_time_percentage': 0,\n",
    "            'n_trades': 0,\n",
    "            'n_wins': 0,\n",
    "            'win_rate': 0,\n",
    "            'cagr': 0,\n",
    "            'sharpe': 0,\n",
    "            'expectancy': 0,\n",
    "        }\n",
    "\n",
    "    return df_trade, trade_stats\n",
    "\n",
    "\n",
    "# =================================\n",
    "# ===== plotting & evaluation =====\n",
    "# =================================\n",
    "\n",
    "def plot_model_metrics(y_true, y_proba):\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "    # 1. Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=axes[0], colorbar=False)\n",
    "\n",
    "    # 2. ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_disp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "    roc_disp.plot(ax=axes[1])\n",
    "\n",
    "    # 3. Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    pr_disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "    pr_disp.plot(ax=axes[2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tscv_eval(X, y, pipe, n_split=5, predict_proba_threshold=0.5):\n",
    "    '''\n",
    "    for evaluations on train set, make sure X and y does not contain anything from the test set (future data), \n",
    "    and use n_split=5 for 5-fold time series cross-validation\n",
    "    '''\n",
    "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_proba >= predict_proba_threshold).astype(int)\n",
    "\n",
    "        print(f'Fold {i+1}:\\n{classification_report(y_test, y_pred)}')\n",
    "\n",
    "        if i == 0:\n",
    "            print('Fold 1 visualized below')\n",
    "            plot_model_metrics(y_test, y_proba)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_prc_with_thresholds(precision, recall, thresholds, avg_precision, threshold_markers=[0, 0.5, 0.6, 0.7], title='Precision-Recall Curve'):\n",
    "    \"\"\"\n",
    "    Plots a Precision-Recall curve and marks specific threshold points.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f\"PR Curve (AP = {avg_precision:.4f})\", lw=2)\n",
    "\n",
    "    for t_val in threshold_markers:\n",
    "        if t_val <= np.max(thresholds) and t_val >= np.min(thresholds):\n",
    "            idx = np.argmin(np.abs(thresholds - t_val))\n",
    "            plt.plot(recall[idx], precision[idx], 'o', label=f'Threshold = {t_val}', markersize=8)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    handles, labels = handles[::-1], labels[::-1]  # Reverse legend order\n",
    "    plt.legend(handles, labels, title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_equity_curve(df_trade, ohlcv, start_date, end_date, title='Equity Curve'):\n",
    "    df_trade['entry_date'] = pd.to_datetime(df_trade['entry_date'])\n",
    "    df_trade['exit_date'] = pd.to_datetime(df_trade['exit_date'])\n",
    "    \n",
    "    # Prepare the index: start with first entry_date, followed by all exit_dates\n",
    "    dates = [df_trade['entry_date'].min()] + df_trade['exit_date'].tolist()\n",
    "    \n",
    "    # Compute cumulative return step by step\n",
    "    returns = (1 + df_trade['return']).cumprod()\n",
    "    returns = pd.Series(data=returns.values, index=df_trade['exit_date'])\n",
    "\n",
    "    # Insert starting value of 1.0 at the first entry date\n",
    "    cumulative_series = pd.concat([\n",
    "        pd.Series([1.0], index=[df_trade['entry_date'].min()]),\n",
    "        returns\n",
    "    ])\n",
    "    \n",
    "    # Sort index and return\n",
    "    cumulative_series = cumulative_series.sort_index()\n",
    "\n",
    "    df = ohlcv.copy()[start_date:end_date]\n",
    "    df['market_cumret'] = (1 + df['close'].pct_change().fillna(0)).cumprod()\n",
    "\n",
    "    # Merge strategy cumulative return\n",
    "    df['strategy_cumret'] = cumulative_series\n",
    "    df['strategy_cumret'] = df['strategy_cumret'].ffill()\n",
    "\n",
    "    # Plot both\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index, df['strategy_cumret'], label='Strategy Equity Curve', marker='o', markersize=2)\n",
    "    plt.plot(df.index, df['market_cumret'], label='Market (Close) Curve', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ===== WRC & MC Simulation =====\n",
    "# ===============================\n",
    "\n",
    "def white_reality_check(strategy_returns: pd.Series, all_strategy_returns: pd.DataFrame, n_bootstrap=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Perform White Reality Check.\n",
    "    \n",
    "    Parameters:\n",
    "        strategy_returns: Series of returns from selected strategy (e.g., with model predictions).\n",
    "        all_strategy_returns: DataFrame of returns from multiple strategies (same time index).\n",
    "        n_bootstrap: Number of bootstrap resamples.\n",
    "    \n",
    "    Returns:\n",
    "        p_value: White Reality Check p-value.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    T = len(strategy_returns)\n",
    "    observed_stat = np.mean(strategy_returns)\n",
    "\n",
    "    max_statistics = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.randint(0, T, T)\n",
    "        boot_sample = all_strategy_returns.iloc[idx]\n",
    "        max_mean = boot_sample.mean(axis=0, skipna=True).max()\n",
    "        max_statistics.append(max_mean)\n",
    "\n",
    "    p_value = np.mean([s >= observed_stat for s in max_statistics])\n",
    "\n",
    "    plt.hist(max_statistics, bins=50, alpha=0.7)\n",
    "    plt.axvline(observed_stat, color='red', linestyle='--', label='Observed Mean')\n",
    "    plt.title(\"White Reality Check\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def monte_carlo_test(strategy_returns: pd.Series, n_sim=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Monte Carlo test by shuffling return series.\n",
    "    \n",
    "    Parameters:\n",
    "        strategy_returns: Series of returns from selected strategy.\n",
    "        n_sim: Number of simulations.\n",
    "    \n",
    "    Returns:\n",
    "        p_value: Monte Carlo p-value.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    strategy_returns = strategy_returns.dropna()\n",
    "    observed_mean = np.mean(strategy_returns)\n",
    "\n",
    "    sim_means = []\n",
    "    for _ in range(n_sim):\n",
    "        shuffled = np.random.choice(strategy_returns.values, size=len(strategy_returns), replace=True)\n",
    "        sim_means.append(np.mean(shuffled))\n",
    "\n",
    "    p_value = np.mean([s >= observed_mean for s in sim_means])\n",
    "\n",
    "    plt.hist(sim_means, bins=50, alpha=0.7)\n",
    "    sns.kdeplot(sim_means, fill=True)\n",
    "    plt.axvline(observed_mean, color='red', linestyle='--', label='Observed Mean')\n",
    "    plt.title(\"Monte Carlo Test\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # print(f\"Observed mean: {observed_mean:.6f}\")\n",
    "    # print(f\"Simulated means (first 10): {sim_means[:10]}\")\n",
    "    # print(f\"Unique simulated means: {len(set(sim_means))}\")\n",
    "    # print(f\"Min: {min(sim_means):.6f}, Max: {max(sim_means):.6f}\")\n",
    "    return p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2b9d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from files/sp500_tickers_sectors_mindates.pkl.\n"
     ]
    }
   ],
   "source": [
    "# set up some constants\n",
    "etfs = {\n",
    "        'spy': market_trend('spy', end_date='2025-06-27', load_csv=False, save_csv=True),\n",
    "        'qqq': market_trend('qqq', end_date='2025-06-27', load_csv=False, save_csv=True),\n",
    "    }\n",
    "# qqq first date is ~2 month later than spy but it won't matter for this project\n",
    "# print(etfs.keys(), [len(i) for i in etfs.values()]) \n",
    "\n",
    "sp500_tickers = get_sp500()\n",
    "df1 = get_sp500_tickers_sectors_mindates(sp500_tickers=sp500_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95efb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector\n",
      "Technology                82\n",
      "Industrials               71\n",
      "Financial Services        68\n",
      "Healthcare                61\n",
      "Consumer Cyclical         56\n",
      "Consumer Defensive        37\n",
      "Utilities                 31\n",
      "Real Estate               31\n",
      "Energy                    22\n",
      "Communication Services    21\n",
      "Basic Materials           20\n",
      "Name: count, dtype: int64\n",
      "sector\n",
      "Technology                75\n",
      "Financial Services        67\n",
      "Industrials               65\n",
      "Healthcare                58\n",
      "Consumer Cyclical         54\n",
      "Consumer Defensive        35\n",
      "Utilities                 29\n",
      "Real Estate               29\n",
      "Energy                    21\n",
      "Communication Services    19\n",
      "Basic Materials           18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['sector'].value_counts())\n",
    "print(df1[df1['mindate'] < datetime.strptime(\"2016-01-01\", \"%Y-%m-%d\").date()]['sector'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56fc783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>243.470001</td>\n",
       "      <td>244.850006</td>\n",
       "      <td>229.955002</td>\n",
       "      <td>229.955002</td>\n",
       "      <td>7579700</td>\n",
       "      <td>rddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-15</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>248.014999</td>\n",
       "      <td>235.789993</td>\n",
       "      <td>242.574997</td>\n",
       "      <td>6434000</td>\n",
       "      <td>rddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-18</th>\n",
       "      <td>241.759995</td>\n",
       "      <td>253.139999</td>\n",
       "      <td>237.539993</td>\n",
       "      <td>245.630005</td>\n",
       "      <td>6933800</td>\n",
       "      <td>rddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>228.179993</td>\n",
       "      <td>238.839996</td>\n",
       "      <td>225.500000</td>\n",
       "      <td>238.220001</td>\n",
       "      <td>8655700</td>\n",
       "      <td>rddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-20</th>\n",
       "      <td>218.369995</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.373993</td>\n",
       "      <td>221.500000</td>\n",
       "      <td>12437823</td>\n",
       "      <td>rddt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 close        high         low        open    volume ticker\n",
       "Date                                                                       \n",
       "2025-08-14  243.470001  244.850006  229.955002  229.955002   7579700   rddt\n",
       "2025-08-15  246.500000  248.014999  235.789993  242.574997   6434000   rddt\n",
       "2025-08-18  241.759995  253.139999  237.539993  245.630005   6933800   rddt\n",
       "2025-08-19  228.179993  238.839996  225.500000  238.220001   8655700   rddt\n",
       "2025-08-20  218.369995  225.000000  205.373993  221.500000  12437823   rddt"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddt = get_data('rddt')\n",
    "rddt.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb73cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ticker': 'rddt',\n",
       " 'sector': 'Communication Services',\n",
       " 'market_cap': 40869253120,\n",
       " 'avg_volume': 7892150,\n",
       " 'beta': None,\n",
       " 'is_sp500': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddtmd = get_metadata('rddt', sp500_tickers=sp500_tickers)\n",
    "rddtmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ffd5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close                     0\n",
      "high                      0\n",
      "low                       0\n",
      "open                      0\n",
      "volume                    0\n",
      "ticker                    0\n",
      "sma30                    29\n",
      "sma10                     9\n",
      "sma_diff                 29\n",
      "sma_slope                10\n",
      "std30                    29\n",
      "bollinger_upper          29\n",
      "bollinger_lower          29\n",
      "percent_b                29\n",
      "bollinger_z              29\n",
      "price_near_lower_bb       0\n",
      "rsi14                    13\n",
      "prod_bollingerz_rsi      29\n",
      "rsi_smooth               15\n",
      "rsi_local_low             0\n",
      "daily_return              1\n",
      "rolling_volatility14     14\n",
      "atr                       0\n",
      "garch_vol                 1\n",
      "year_since                0\n",
      "month                     0\n",
      "week                      0\n",
      "dayofweek                 0\n",
      "macd_diff                33\n",
      "adx                       0\n",
      "adx_pos                   0\n",
      "adx_neg                   0\n",
      "strong_trend              0\n",
      "up_trend_context          0\n",
      "down_trend_context        0\n",
      "spy_trend_10_50          37\n",
      "spy_trend_20_50          37\n",
      "spy_trend_50_200         37\n",
      "qqq_trend_10_50          37\n",
      "qqq_trend_20_50          37\n",
      "qqq_trend_50_200         37\n",
      "sector                    0\n",
      "market_cap                0\n",
      "avg_volume                0\n",
      "beta                    355\n",
      "is_sp500                  0\n",
      "target_long               5\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sma30</th>\n",
       "      <th>sma10</th>\n",
       "      <th>sma_diff</th>\n",
       "      <th>sma_slope</th>\n",
       "      <th>std30</th>\n",
       "      <th>bollinger_upper</th>\n",
       "      <th>bollinger_lower</th>\n",
       "      <th>percent_b</th>\n",
       "      <th>bollinger_z</th>\n",
       "      <th>price_near_lower_bb</th>\n",
       "      <th>rsi14</th>\n",
       "      <th>prod_bollingerz_rsi</th>\n",
       "      <th>rsi_smooth</th>\n",
       "      <th>rsi_local_low</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>rolling_volatility14</th>\n",
       "      <th>atr</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>year_since</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>macd_diff</th>\n",
       "      <th>adx</th>\n",
       "      <th>adx_pos</th>\n",
       "      <th>adx_neg</th>\n",
       "      <th>strong_trend</th>\n",
       "      <th>up_trend_context</th>\n",
       "      <th>down_trend_context</th>\n",
       "      <th>spy_trend_10_50</th>\n",
       "      <th>spy_trend_20_50</th>\n",
       "      <th>spy_trend_50_200</th>\n",
       "      <th>qqq_trend_10_50</th>\n",
       "      <th>qqq_trend_20_50</th>\n",
       "      <th>qqq_trend_50_200</th>\n",
       "      <th>sector</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>avg_volume</th>\n",
       "      <th>beta</th>\n",
       "      <th>is_sp500</th>\n",
       "      <th>target_long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>243.470001</td>\n",
       "      <td>244.850006</td>\n",
       "      <td>229.955002</td>\n",
       "      <td>229.955002</td>\n",
       "      <td>7579700</td>\n",
       "      <td>rddt</td>\n",
       "      <td>170.392334</td>\n",
       "      <td>215.257001</td>\n",
       "      <td>44.864666</td>\n",
       "      <td>8.288</td>\n",
       "      <td>33.759198</td>\n",
       "      <td>237.910731</td>\n",
       "      <td>102.873938</td>\n",
       "      <td>1.041169</td>\n",
       "      <td>2.164674</td>\n",
       "      <td>0</td>\n",
       "      <td>87.984832</td>\n",
       "      <td>91.607040</td>\n",
       "      <td>86.407406</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>11.291711</td>\n",
       "      <td>4.642381</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>6.006136</td>\n",
       "      <td>44.456127</td>\n",
       "      <td>43.852888</td>\n",
       "      <td>6.177464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>40869253120</td>\n",
       "      <td>7892150</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-15</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>248.014999</td>\n",
       "      <td>235.789993</td>\n",
       "      <td>242.574997</td>\n",
       "      <td>6434000</td>\n",
       "      <td>rddt</td>\n",
       "      <td>173.374668</td>\n",
       "      <td>221.043001</td>\n",
       "      <td>47.668333</td>\n",
       "      <td>5.786</td>\n",
       "      <td>36.387671</td>\n",
       "      <td>246.150011</td>\n",
       "      <td>100.599325</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>2.009618</td>\n",
       "      <td>0</td>\n",
       "      <td>88.427390</td>\n",
       "      <td>88.640021</td>\n",
       "      <td>87.677632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054880</td>\n",
       "      <td>0.046663</td>\n",
       "      <td>11.358375</td>\n",
       "      <td>4.518337</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>5.790437</td>\n",
       "      <td>46.732505</td>\n",
       "      <td>42.471890</td>\n",
       "      <td>5.702550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>40869253120</td>\n",
       "      <td>7892150</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-18</th>\n",
       "      <td>241.759995</td>\n",
       "      <td>253.139999</td>\n",
       "      <td>237.539993</td>\n",
       "      <td>245.630005</td>\n",
       "      <td>6933800</td>\n",
       "      <td>rddt</td>\n",
       "      <td>176.321001</td>\n",
       "      <td>225.043001</td>\n",
       "      <td>48.722000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>38.243212</td>\n",
       "      <td>252.807426</td>\n",
       "      <td>99.834576</td>\n",
       "      <td>0.927782</td>\n",
       "      <td>1.711127</td>\n",
       "      <td>0</td>\n",
       "      <td>83.260825</td>\n",
       "      <td>77.247873</td>\n",
       "      <td>86.557682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.046309</td>\n",
       "      <td>11.661348</td>\n",
       "      <td>4.674655</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4.870647</td>\n",
       "      <td>48.959931</td>\n",
       "      <td>41.552725</td>\n",
       "      <td>5.157650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>40869253120</td>\n",
       "      <td>7892150</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>228.179993</td>\n",
       "      <td>238.839996</td>\n",
       "      <td>225.500000</td>\n",
       "      <td>238.220001</td>\n",
       "      <td>8655700</td>\n",
       "      <td>rddt</td>\n",
       "      <td>179.061667</td>\n",
       "      <td>227.952000</td>\n",
       "      <td>48.890333</td>\n",
       "      <td>2.909</td>\n",
       "      <td>38.932295</td>\n",
       "      <td>256.926256</td>\n",
       "      <td>101.197078</td>\n",
       "      <td>0.815409</td>\n",
       "      <td>1.261634</td>\n",
       "      <td>0</td>\n",
       "      <td>70.543946</td>\n",
       "      <td>57.522142</td>\n",
       "      <td>80.744053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.030167</td>\n",
       "      <td>0.045324</td>\n",
       "      <td>11.989823</td>\n",
       "      <td>4.532939</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2.982513</td>\n",
       "      <td>49.181486</td>\n",
       "      <td>37.527603</td>\n",
       "      <td>11.830785</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>40869253120</td>\n",
       "      <td>7892150</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-20</th>\n",
       "      <td>218.369995</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.373993</td>\n",
       "      <td>221.500000</td>\n",
       "      <td>12437823</td>\n",
       "      <td>rddt</td>\n",
       "      <td>181.485667</td>\n",
       "      <td>228.508000</td>\n",
       "      <td>47.022333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>39.043969</td>\n",
       "      <td>259.573606</td>\n",
       "      <td>103.397729</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.944687</td>\n",
       "      <td>0</td>\n",
       "      <td>63.052034</td>\n",
       "      <td>46.417125</td>\n",
       "      <td>72.285602</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070187</td>\n",
       "      <td>0.049152</td>\n",
       "      <td>12.762407</td>\n",
       "      <td>4.598510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.820214</td>\n",
       "      <td>47.135000</td>\n",
       "      <td>32.737561</td>\n",
       "      <td>21.584810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>40869253120</td>\n",
       "      <td>7892150</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 close        high         low        open    volume ticker  \\\n",
       "Date                                                                          \n",
       "2025-08-14  243.470001  244.850006  229.955002  229.955002   7579700   rddt   \n",
       "2025-08-15  246.500000  248.014999  235.789993  242.574997   6434000   rddt   \n",
       "2025-08-18  241.759995  253.139999  237.539993  245.630005   6933800   rddt   \n",
       "2025-08-19  228.179993  238.839996  225.500000  238.220001   8655700   rddt   \n",
       "2025-08-20  218.369995  225.000000  205.373993  221.500000  12437823   rddt   \n",
       "\n",
       "                 sma30       sma10   sma_diff  sma_slope      std30  \\\n",
       "Date                                                                  \n",
       "2025-08-14  170.392334  215.257001  44.864666      8.288  33.759198   \n",
       "2025-08-15  173.374668  221.043001  47.668333      5.786  36.387671   \n",
       "2025-08-18  176.321001  225.043001  48.722000      4.000  38.243212   \n",
       "2025-08-19  179.061667  227.952000  48.890333      2.909  38.932295   \n",
       "2025-08-20  181.485667  228.508000  47.022333      0.556  39.043969   \n",
       "\n",
       "            bollinger_upper  bollinger_lower  percent_b  bollinger_z  \\\n",
       "Date                                                                   \n",
       "2025-08-14       237.910731       102.873938   1.041169     2.164674   \n",
       "2025-08-15       246.150011       100.599325   1.002405     2.009618   \n",
       "2025-08-18       252.807426        99.834576   0.927782     1.711127   \n",
       "2025-08-19       256.926256       101.197078   0.815409     1.261634   \n",
       "2025-08-20       259.573606       103.397729   0.736172     0.944687   \n",
       "\n",
       "            price_near_lower_bb      rsi14  prod_bollingerz_rsi  rsi_smooth  \\\n",
       "Date                                                                          \n",
       "2025-08-14                    0  87.984832            91.607040   86.407406   \n",
       "2025-08-15                    0  88.427390            88.640021   87.677632   \n",
       "2025-08-18                    0  83.260825            77.247873   86.557682   \n",
       "2025-08-19                    0  70.543946            57.522142   80.744053   \n",
       "2025-08-20                    0  63.052034            46.417125   72.285602   \n",
       "\n",
       "            rsi_local_low  daily_return  rolling_volatility14        atr  \\\n",
       "Date                                                                       \n",
       "2025-08-14              0      0.017860              0.046927  11.291711   \n",
       "2025-08-15              0      0.054880              0.046663  11.358375   \n",
       "2025-08-18              0      0.012594              0.046309  11.661348   \n",
       "2025-08-19              0     -0.030167              0.045324  11.989823   \n",
       "2025-08-20              0     -0.070187              0.049152  12.762407   \n",
       "\n",
       "            garch_vol  year_since  month  week  dayofweek  macd_diff  \\\n",
       "Date                                                                   \n",
       "2025-08-14   4.642381           1      8    33          3   6.006136   \n",
       "2025-08-15   4.518337           1      8    33          4   5.790437   \n",
       "2025-08-18   4.674655           1      8    34          0   4.870647   \n",
       "2025-08-19   4.532939           1      8    34          1   2.982513   \n",
       "2025-08-20   4.598510           1      8    34          2   0.820214   \n",
       "\n",
       "                  adx    adx_pos    adx_neg  strong_trend  up_trend_context  \\\n",
       "Date                                                                          \n",
       "2025-08-14  44.456127  43.852888   6.177464             1                 1   \n",
       "2025-08-15  46.732505  42.471890   5.702550             1                 1   \n",
       "2025-08-18  48.959931  41.552725   5.157650             1                 1   \n",
       "2025-08-19  49.181486  37.527603  11.830785             1                 1   \n",
       "2025-08-20  47.135000  32.737561  21.584810             1                 1   \n",
       "\n",
       "            down_trend_context  spy_trend_10_50  spy_trend_20_50  \\\n",
       "Date                                                               \n",
       "2025-08-14                   0              NaN              NaN   \n",
       "2025-08-15                   0              NaN              NaN   \n",
       "2025-08-18                   0              NaN              NaN   \n",
       "2025-08-19                   0              NaN              NaN   \n",
       "2025-08-20                   0              NaN              NaN   \n",
       "\n",
       "            spy_trend_50_200  qqq_trend_10_50  qqq_trend_20_50  \\\n",
       "Date                                                             \n",
       "2025-08-14               NaN              NaN              NaN   \n",
       "2025-08-15               NaN              NaN              NaN   \n",
       "2025-08-18               NaN              NaN              NaN   \n",
       "2025-08-19               NaN              NaN              NaN   \n",
       "2025-08-20               NaN              NaN              NaN   \n",
       "\n",
       "            qqq_trend_50_200                  sector   market_cap  avg_volume  \\\n",
       "Date                                                                            \n",
       "2025-08-14               NaN  Communication Services  40869253120     7892150   \n",
       "2025-08-15               NaN  Communication Services  40869253120     7892150   \n",
       "2025-08-18               NaN  Communication Services  40869253120     7892150   \n",
       "2025-08-19               NaN  Communication Services  40869253120     7892150   \n",
       "2025-08-20               NaN  Communication Services  40869253120     7892150   \n",
       "\n",
       "            beta  is_sp500  target_long  \n",
       "Date                                     \n",
       "2025-08-14  None     False         <NA>  \n",
       "2025-08-15  None     False         <NA>  \n",
       "2025-08-18  None     False         <NA>  \n",
       "2025-08-19  None     False         <NA>  \n",
       "2025-08-20  None     False         <NA>  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddtwr = wrangling(\n",
    "    rddt, \n",
    "    etfs=etfs, \n",
    "    sp500_tickers=sp500_tickers, \n",
    ")\n",
    "print(rddtwr.isna().sum())\n",
    "rddtwr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14b80a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "close                    0\n",
       "high                     0\n",
       "low                      0\n",
       "open                     0\n",
       "volume                   0\n",
       "ticker                   0\n",
       "sma30                   29\n",
       "sma10                    9\n",
       "sma_diff                29\n",
       "sma_slope               10\n",
       "std30                   29\n",
       "bollinger_upper         29\n",
       "bollinger_lower         29\n",
       "percent_b               29\n",
       "bollinger_z             29\n",
       "price_near_lower_bb      0\n",
       "rsi14                   13\n",
       "prod_bollingerz_rsi     29\n",
       "rsi_smooth              15\n",
       "rsi_local_low            0\n",
       "daily_return             1\n",
       "rolling_volatility14    14\n",
       "atr                      0\n",
       "garch_vol                1\n",
       "year_since               0\n",
       "month                    0\n",
       "week                     0\n",
       "dayofweek                0\n",
       "macd_diff               33\n",
       "adx                      0\n",
       "adx_pos                  0\n",
       "adx_neg                  0\n",
       "strong_trend             0\n",
       "up_trend_context         0\n",
       "down_trend_context       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddtfe = feature_engineering(rddt)\n",
    "print(len(rddtfe))\n",
    "rddtfe.tail()\n",
    "rddtfe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f05339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpsc330arm)",
   "language": "python",
   "name": "cpsc330arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
